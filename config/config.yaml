# ═══════════════════════════════════════════════════════════════
#                    TrendRadar 配置文件
#                      Version: 1.0.0
# ═══════════════════════════════════════════════════════════════


# ===============================================================
# 1. 基础设置
# ===============================================================
app:
  # 时区配置（影响所有时间显示、推送窗口判断、数据存储）
  # 常用时区：
  #   - Asia/Shanghai (北京时间 UTC+8)
  #   - America/New_York (美东时间 UTC-5/-4)
  #   - Europe/London (伦敦时间 UTC+0/+1)
  # 完整时区列表: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
  timezone: "Asia/Shanghai"
  show_version_update: true           # 显示版本更新提示


# ===============================================================
# 2. 数据源 - 热榜平台
#
# enabled: 是否启用热榜抓取（总开关）
# sources: 平台列表
#   - id: 平台唯一标识（勿修改）
#   - name: 显示名称（可自定义，修改后不影响运行）
# ===============================================================
platforms:
  enabled: true                         # 是否启用热榜平台抓取
  sources:
    - id: "weibo"
      name: "微博热搜"                # 品牌翻车、官宣代言通常在这里最先爆
    
    - id: "douyin"
      name: "抖音热榜"                # 抓“爆款单品”和“仿妆趋势”
    
    - id: "xiaohongshu"
      name: "小红书"                  # 美妆种草的大本营 (如果支持的话)
      
    - id: "zhihu"
      name: "知乎热榜"                # 抓“成分党”和“技术分析”的舆论



# ===============================================================
# 3. 数据源 - RSS 订阅
#
# 与热榜数据分开存储，按时间流展示
# 每个源配置：id(唯一标识)、name(显示名称)、url(订阅地址)
# enabled: 可选，默认 true
# max_age_days: 可选，覆盖全局 freshness_filter.max_age_days
# ===============================================================
# ===============================================================
# 3. 数据源 - RSS 订阅 (已改为美妆雷达模式)
# ===============================================================
rss:
  enabled: true                       # 🟢 必须开启

  # 新鲜度过滤：只看最近 48 小时的新闻，保证播客的时效性
  freshness_filter:
    enabled: true
    max_age_days: 2                   # 建议设为 2 天 (太久以前的新闻没必要讲)

  feeds:
    # --- 核心源 1：Yahoo 香港搜索 (繁体中文，聚合能力极强，主力军) ---
    # 它可以搜到大量港台及内地关于“化妝品”的报道，且不反爬
    - id: "yahoo-cosmetics"
      name: "全网搜-化妆品(Yahoo)"
      url: "https://hk.news.yahoo.com/rss/search?p=化妝品"

    # --- 核心源 2：Bing 行业搜索 (精准匹配) ---
    # 专门搜“行业”动态，过滤掉普通的产品广告
    - id: "bing-industry"
      name: "全网搜-化妆品行业(Bing)"
      url: "https://www.bing.com/news/search?q=化妆品+行业&format=RSS"

    # --- 核心源 3：Bing 监管搜索 (专家人设必备) ---
    # 专门抓药监局通告、不合格通报、法规变动
    - id: "bing-nmpa"
      name: "全网搜-药监局通告(Bing)"
      url: "https://www.bing.com/news/search?q=国家药监局+化妆品+通告&format=RSS"

    # --- 辅助源：36氪 (商业动态) ---
    # 虽然它是全站内容，但 TrendRadar 会用关键词(frequency_words.txt)把美妆内容筛出来
    - id: "36kr-feed"
      name: "36氪"
      url: "https://www.36kr.com/feed"

# ===============================================================
# 4. 报告模式
#
# 🔸 daily（当日汇总模式）
#    • 推送时机：按时推送(默认每小时推送一次)
#    • 显示内容：当日所有匹配新闻 + 新增新闻区域
#    • 适用场景：日报总结、全面了解当日热点趋势
#
# 🔸 current（当前榜单模式）
#    • 推送时机：按时推送(默认每小时推送一次)
#    • 显示内容：当前榜单匹配新闻 + 新增新闻区域
#    • 适用场景：实时热点追踪、了解当前最火的内容
#
# 🔸 incremental（增量监控模式）
#    • 推送时机：有新增才推送
#    • 显示内容：新出现的匹配频率词新闻
#    • 适用场景：避免重复信息干扰
# ===============================================================
report:
  mode: "current"                     # 可选: daily | current | incremental
  display_mode: "keyword"             # 分组维度: keyword | platform
                                      # keyword: 按关键词分组显示（默认）
                                      # platform: 按平台/来源分组显示

  # 关键词组排序方式（仅 display_mode: keyword 时生效）
  # true: 按 frequency_words.txt 中的定义顺序排列
  # false: 按匹配到的热点条数排序（条数多的在前）
  sort_by_position_first: false

  rank_threshold: 5                   # 排名高亮阈值

  max_news_per_keyword: 0             # 每个关键词最大显示数量（0=不限制）


# ===============================================================
# 5. 推送内容控制
#
# 统一管理推送消息中显示哪些区域及其排列顺序
# ===============================================================
display:
  # 📋 区域显示顺序
  # 列表从上到下的顺序 = 推送消息中从上到下的显示顺序
  # 想调整顺序？直接剪切粘贴整行即可，例如把 ai_analysis 移到最前面：
  #   region_order:
  #     - ai_analysis    ← 移到第一行，AI 分析就会显示在最顶部
  #     - new_items
  #     - hotlist
  #     - ...
  # 注意：区域需同时满足两个条件才会显示：
  #   1. 在此列表中
  #   2. 下方 regions 中对应开关为 true
  region_order:
    - new_items                       # 1️⃣ 新增热点区域
    - hotlist                         # 2️⃣ 热榜区域（关键词匹配）
    - rss                             # 3️⃣ RSS 订阅区域
    - standalone                      # 4️⃣ 独立展示区
    - ai_analysis                     # 5️⃣ AI 分析区域

  # 推送区域开关
  # 控制各区域是否启用（配合 region_order 使用）
  regions:
    hotlist: true                     # 热榜区域（关键词匹配的热点新闻）
    new_items: true                   # 新增热点区域（含热榜新增 + RSS 新增）
                                      # 注：热点词汇统计中的新增标记🆕不受此配置影响

    rss: false                         # RSS 订阅区域
                                      # 开启后将对 RSS 进行关键词分析并在通知中展示
                                      # 关闭后跳过分析，但独立展示区不受影响

    standalone: false                 # 独立展示区（完整热榜/RSS，不受关键词过滤）
    ai_analysis: true                 # AI 分析区域

  # 📋 独立展示区配置（仅在 regions.standalone: true 时生效）
  # 用途：将指定平台的完整热榜/RSS 单独展示，不受关键词过滤影响
  # 适用场景：
  #   - 想完整查看某个平台的热榜排名
  #   - RSS 源内容较少，希望全部展示而非只显示关键词匹配的
  # 注意：同一新闻可能同时出现在关键词匹配区和独立展示区
  standalone:
    platforms: []                     # 热榜平台 ID 列表（如 ["zhihu", "weibo"]）
    rss_feeds: []                     # RSS 源 ID 列表（如 ["hacker-news"]）
    max_items: 20                     # 每个源最多展示条数（0=不限制）


# ===============================================================
# 6. 推送通知
#
# ⚠️ 重要安全警告 ⚠️
#
# 🔴 请务必妥善保管好 webhooks，不要公开!!!
# 🔴 如果你以 fork 的方式部署在 GitHub 上，请勿在此填写
# 🔴 而是将 webhooks 填入 GitHub Secrets
#    (Settings → Secrets and variables → Actions)
# 🔴 否则：
#    - 轻则：手机上收到大量垃圾广告推送
#    - 重则：webhook 被滥用造成严重安全隐患
#
# 📌 多账号支持说明
#
# • 使用分号(;)分隔多个账号，如："url1;url2;url3"
# • 需要配对的配置（如 Telegram 的 token 和 chat_id）数量必须一致
# • 每个渠道最多支持 max_accounts_per_channel 个账号
# • 邮箱已支持多收件人（逗号分隔）
# ===============================================================
notification:
  enabled: true                       # 是否启用通知功能

  # 🕐 推送时间窗口控制（可选功能）
  # 用途：限制推送的时间范围，避免非工作时间打扰
  # 适用场景：
  #   • 只想在工作日白天接收推送（如 09:00-18:00）
  #   • 希望在晚上固定时间收到汇总（如 20:00-22:00）
  # ⚠️ GitHub Actions 用户注意：
  #   执行时间不稳定，时间范围建议至少留足 2 小时
  # 💡 想要精准定时？建议使用 Docker 部署在个人服务器上
  push_window:
    enabled: false                    # 是否启用推送时间窗口控制
    start: "20:00"                    # 开始时间（北京时间）
    end: "22:00"                      # 结束时间（北京时间）
    once_per_day: true                # true=窗口内只推送一次，false=窗口内每次执行都推送

  # 推送渠道配置
  channels:
    feishu:
      webhook_url: ""                 # 飞书机器人 webhook URL

    dingtalk:
      webhook_url: ""                 # 钉钉机器人 webhook URL

    wework:
      webhook_url: ""                 # 企业微信机器人 webhook URL
      msg_type: "markdown"            # 消息类型：markdown(群机器人) | text(个人微信应用)

    telegram:
      bot_token: ""                   # Telegram Bot Token
      chat_id: ""                     # Telegram Chat ID

    email:
      from: ""                        # 发件人邮箱地址
      password: ""                    # 发件人邮箱密码或授权码
      to: ""                          # 收件人邮箱，多个用逗号分隔
      smtp_server: ""                 # SMTP 服务器（可选，留空自动识别）
      smtp_port: ""                   # SMTP 端口（可选，留空自动识别）

    ntfy:
      server_url: "https://ntfy.sh"   # ntfy 服务器地址（可改为自托管）
      topic: ""                       # ntfy 主题名称
      token: ""                       # ntfy 访问令牌（可选，用于私有主题）

    bark:
      url: ""                         # Bark 推送 URL（格式：https://api.day.app/your_device_key）

    slack:
      webhook_url: ""                 # Slack Incoming Webhook URL

    generic_webhook:
      webhook_url: ""                 # 通用 Webhook URL（支持 Discord、Matrix、IFTTT 等）
      payload_template: ""            # JSON 模板，支持 {title} 和 {content} 占位符
                                      # 示例：{"content": "{content}"}
                                      # 留空则使用默认格式：{"title": "{title}", "content": "{content}"}


# ===============================================================
# 7. 存储配置
# ===============================================================
storage:
  # 存储后端选择
  # - auto: 自动选择（GitHub Actions 且配置了远程存储 → remote，否则 → local）
  # - local: 本地 SQLite + TXT/HTML 文件
  # - remote: 远程云存储（S3 兼容协议，支持 R2/OSS/COS 等）
  backend: "auto"

  # 数据格式选项
  formats:
    sqlite: true                      # 主存储（必须启用）
    txt: false                        # 是否生成 TXT 快照
    html: true                       # 是否生成 HTML 报告（⚠️ 邮件推送或者需要看网页版报告必须设为 true）

  # 本地存储配置
  local:
    data_dir: "output"                # 数据目录
    retention_days: 0                 # 保留天数（0=永久保留）

  # 远程存储配置（S3 兼容协议）
  # 支持: Cloudflare R2, 阿里云 OSS, 腾讯云 COS, AWS S3, MinIO 等
  # 建议将敏感信息配置在 GitHub Secrets 或环境变量中
  remote:
    retention_days: 0                 # 保留天数（0=永久保留）

    # S3 兼容配置（或使用环境变量 S3_ENDPOINT_URL 等）
    endpoint_url: ""                  # 服务端点
                                      # Cloudflare R2: https://<account_id>.r2.cloudflarestorage.com
                                      # 阿里云 OSS: https://oss-cn-hangzhou.aliyuncs.com
                                      # 腾讯云 COS: https://cos.ap-guangzhou.myqcloud.com
    bucket_name: ""                   # 存储桶名称
    access_key_id: ""                 # 访问密钥 ID
    secret_access_key: ""             # 访问密钥
    region: ""                        # 区域（可选，部分服务商需要）

  # 数据拉取配置（从远程同步到本地）
  # 用于 MCP Server 等场景：爬虫存到远程，MCP 拉取到本地分析
  pull:
    enabled: false                    # 是否启用启动时自动拉取
    days: 7                           # 拉取最近 N 天的数据


# ===============================================================
# 8. AI 模型配置（共享）
#
# ai_analysis 和 ai_translation 共用此模型配置
# 基于 LiteLLM 统一接口，支持 100+ AI 提供商
# ===============================================================
ai:
  # LiteLLM 模型格式: provider/model_name
  # 示例:
  #   - deepseek/deepseek-chat (DeepSeek)
  #   - openai/gpt-4o (OpenAI)
  #   - gemini/gemini-2.5-flash (Google Gemini)
  #   - anthropic/claude-3-5-sonnet (Anthropic)
  #   - ollama/llama3 (本地 Ollama)
  # 完整列表: https://docs.litellm.ai/docs/providers
  # 如果你对于看英文文档比较头疼，那么可以点击页面右下角的 【Ask AI】 ,用中文询问怎么配置 
  
  model: "deepseek/deepseek-chat"

  api_key: ""                       # API Key（建议使用环境变量 AI_API_KEY）
  
  api_base: ""                      # 自定义 API 端点（可选，大多数情况留空）
                                    # 示例: https://api.openai.com/v1（自建代理或兼容接口）
                                    #
                                    # 💡 超级重要：连接任意兼容 OpenAI 协议的模型商
                                    # 如果你使用的模型商不在上述支持列表中，但提供了兼容 OpenAI 的接口：
                                    #
                                    # 1. api_base 填写: 服务商提供的接口地址
                                    #    例如: https://api.example.com/v1
                                    #
                                    # 2. model 填写: "openai/" + 实际模型名称
                                    #    例如: openai/deepseek-ai/DeepSeek-V3
                                    #    (原理：前缀 openai/ 强制 LiteLLM 使用 OpenAI 协议格式进行通信)


  timeout: 120                      # 请求超时（秒）

  temperature: 1.0                  # 采样温度 (0.0-2.0)
                                    # 注意：部分模型(如 gpt-5)可能要求必须为 1.0，否则会报错
  
  max_tokens: 5000                  # 最大生成 token 数
                                    # 注意：如果 API 不支持此参数(报 HTTP 400)，请设为 0 以禁用发送
  # 高级选项
  num_retries: 1                    # 失败重试次数
  fallback_models: []               # 备用模型列表（可选）
                                    # 示例: ["openai/gpt-4o-mini", "openai/deepseek-ai/DeepSeek-V3"]

  # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  # 额外参数 (高级选项，一般无需修改)
  # ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  # LiteLLM 会自动将通用参数转换为各提供商格式，无需手动适配。
  # 仅在需要传递特殊参数时启用此项。
  #
  # 提示：你可以根据模型 API 文档自行添加任何支持的字段。
  # 操作：如需启用，请删掉该行最前方的 "# "（井号和空格）。
  # 注意：如果这几行都带着井号，则代表不使用额外参数（推荐做法）。
  # -------------------------------------------------------------
  # extra_params:
  #   top_p: 1.0              # 核采样（通用）
  #   presence_penalty: 0.0   # 话题多样性（OpenAI/DeepSeek）
  #   stop: ["END"]           # 停止词列表（通用）


# ===============================================================
# 9. AI 分析功能
#
# 使用 AI 大模型对推送内容进行深度分析
# 模型配置见上方 ai 配置段
# ===============================================================
ai_analysis:
  enabled: true                     # 是否启用 AI 分析

  # 🕐 AI 分析时间窗口控制（可选功能）
  # 用途：限制 AI 分析的时间范围，避免非必要时段消耗 API 额度
  # 适用场景：
  #   • 只在工作时间进行 AI 分析（如 09:00-18:00）
  #   • 在特定时段进行深度分析（如 20:00-22:00）
  # ⚠️ GitHub Actions 用户注意：
  #   执行时间不稳定，时间范围建议至少留足 2 小时
  # 💡 想要精准定时？建议使用 Docker 部署在个人服务器上
  analysis_window:
    enabled: false                  # 是否启用 AI 分析时间窗口控制
    start: "12:00"                  # 开始时间（使用 app.timezone 配置的时区）
    end: "21:00"                    # 结束时间（使用 app.timezone 配置的时区）
    once_per_day: false             # true=窗口内只分析一次，false=窗口内每次执行都分析

  # 分析报告输出语言
  # 格式：自然语言描述
  # 示例: "English", "Korean", "法语"
  language: "Chinese"

  # 提示词配置文件路径（相对于 config 目录）
  prompt_file: "ai_analysis_prompt.txt"

  # AI 分析模式（独立于推送报告模式）
  # 可选值:
  #   - "follow_report": 跟随 report.mode 的设置（默认）
  #   - "daily": 强制使用当日汇总模式（分析当天所有新闻）
  #   - "current": 强制使用当前榜单模式（只分析当前在榜新闻）
  #   - "incremental": 强制使用增量模式（只分析新增新闻）
  #
  # 使用场景：
  #   - 推送 incremental（避免重复），AI 分析 current（看当前榜单变化）
  #   - 推送 current（实时热点），AI 分析 daily（全天总结）
  #
  mode: "follow_report"

  # 分析内容配置
  max_news_for_analysis: 60         # 参与分析的新闻数量上限（控制成本关键项）
                                    # 推送消息顶部会显示实际的 AI 分析数供参考

                                    # api 成本估算 (仅供参考)
                                      # 按默认模型(deepseek)
                                      # max_news_for_analysis 为 50 条
                                      # include_rank_timeline 为 false
                                    # 则
                                      # GitHub Action 部署默认推送约 20 次（每小时推送一次）， 约 0.1 元/天
                                      # Docker 部署默认推送 48 次(每半小时推送一次)， 约 0.2 元/天

  include_rss: false                 # 是否包含 RSS 内容进行分析

  include_rank_timeline: true      # 是否传递完整排名时间线
                                    # false: 使用简化格式（排名范围+时间范围+出现次数）
                                    # true: 传递完整排名变化轨迹（如 1(09:30)→2(10:00)→0(11:00)）
                                    # 启用后 AI 能更精确分析热度趋势，但会额外增加 token 消耗（0.5 倍到 1 倍）


# ===============================================================
# 10. AI 翻译功能
#
# 对推送内容进行多语言翻译，不包含 ai_analysis 分析的内容 
# 模型配置见上方 ai 配置段
# ===============================================================
ai_translation:
  enabled: false                    # 是否启用翻译功能

  # 翻译目标语言
  # 格式：自然语言描述
  # 示例: "Chinese", "Korean", "法语"
  language: "English"

  # 提示词配置文件路径（相对于 config 目录）
  prompt_file: "ai_translation_prompt.txt"


# ===============================================================
# 11. 高级设置（一般无需修改）
# ===============================================================
advanced:
  # 调试模式
  debug: false

  # 版本检查
  version_check_url: "https://raw.githubusercontent.com/sansan0/TrendRadar/refs/heads/master/version"
  mcp_version_check_url: "https://raw.githubusercontent.com/sansan0/TrendRadar/refs/heads/master/version_mcp"
  configs_version_check_url: "https://raw.githubusercontent.com/sansan0/TrendRadar/refs/heads/master/version_configs"

  # 热榜爬虫技术参数
  crawler:
    request_interval: 2000            # 请求间隔（毫秒）
    use_proxy: false                  # 是否启用代理
    default_proxy: "http://127.0.0.1:10801"

  # RSS 设置
  rss:
    request_interval: 1000            # 请求间隔（毫秒）
    timeout: 15                       # 请求超时（秒）
    use_proxy: false                  # 是否使用代理
    proxy_url: ""                     # RSS 专属代理（留空则使用 crawler.default_proxy）

  # 排序权重（用于重新排序不同平台的热搜）
  # 合起来等于 1
  weight:
    rank: 0.6                         # 排名权重
    frequency: 0.3                    # 频次权重
    hotness: 0.1                      # 热度权重

  # 多账号限制
  max_accounts_per_channel: 3         # 每个渠道最大账号数量

  # 消息分批大小（字节）- 内部配置，请勿修改
  batch_size:
    default: 4000
    dingtalk: 20000
    feishu: 30000
    bark: 4000
    slack: 4000
  batch_send_interval: 3              # 批次发送间隔（秒）
  feishu_message_separator: "━━━━━━━━━━━━━━━━━━━"
